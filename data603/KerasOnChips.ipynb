{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Run Keras Models in Parallel with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /scratch/data603/klucar/data603/SparkLauncher.ipynb\n",
      "Creating Spark Configuration\n",
      "Creating Spark Configuration\n",
      "Setting Environment Variables\n",
      "Creating Spark Session: klucar_data603_spark_session\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from data603 import SparkLauncher\n",
    "\n",
    "# get a configuration object\n",
    "conf = SparkLauncher.get_spark_conf()\n",
    "\n",
    "# add a file to the configuration that will get copied to all the nodes on the cluster\n",
    "conf.set('spark.yarn.dist.files', './keras_data/mobilenet_1_0_224_tf.h5')\n",
    "\n",
    "# launch the cluster using the configuration\n",
    "spark = SparkLauncher.get_spark_session(pack_venv = False, conf = conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "image_chips = spark.read.parquet(\"/user/klucar/image_chips.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10176"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_chips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_chips.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Run Keras on Image Chip Data\n",
    "\n",
    "Similar to how the image chips were extracted and how they were written to HDFS, run a Keras prediction model on the image chip. This evaluate chip code is a UDF that encapsulates the Keras model running code from another notebook.\n",
    "\n",
    "What's new about this particular UDF is that it returns a MapType. This map is the predicted label and the predicted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_chip(chip_data):\n",
    "    import io\n",
    "    import os\n",
    "    from keras.applications.mobilenet import MobileNet\n",
    "    from keras.applications.mobilenet import preprocess_input\n",
    "    from keras.applications.mobilenet import decode_predictions\n",
    "    from keras.preprocessing.image import load_img\n",
    "    from keras.preprocessing.image import img_to_array\n",
    "\n",
    "    # Load the image\n",
    "    img = load_img(io.BytesIO(chip_data), target_size = (224,224))\n",
    "\n",
    "    # Prepare Image\n",
    "    image = img_to_array(img)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    # Load Model Data\n",
    "    model = MobileNet(weights = f'{os.getcwd()}/mobilenet_1_0_224_tf.h5',\n",
    "                 include_top = True,\n",
    "                 alpha = 1.0)\n",
    "    \n",
    "    # Run prediction\n",
    "    yhat = model.predict(image)\n",
    "\n",
    "    # Decode Predictions\n",
    "    label = decode_predictions(yhat)\n",
    "    label = label[0][0]\n",
    "\n",
    "    ret = {label[1]: float(label[2])}   \n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wrap Keras Evaluation in a UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# make a UDF\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "schema = MapType(StringType(), DoubleType())\n",
    "\n",
    "udf_evaluate_chip = udf(evaluate_chip, schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## apply the udf to the chip_data row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# get rid of the original image data\n",
    "image_chips = image_chips.drop('Data')\n",
    "\n",
    "# evaluate image chips\n",
    "image_chips = image_chips.withColumn(\"prediction\", udf_evaluate_chip(\"chip_data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Force UDF Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import map_keys\n",
    "from pyspark.sql.functions import map_values\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Extract the prediction labels and confidence values from the returned map\n",
    "predictions = image_chips.select(explode(col(\"prediction\")).alias(\"predicted_label\", \"predicted_score\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "preds = predictions.groupby('predicted_label').count().sort(col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|     predicted_label|count|\n",
      "+--------------------+-----+\n",
      "|               goose| 2098|\n",
      "|             ostrich|  587|\n",
      "|red-breasted_merg...|  583|\n",
      "|               drake|  462|\n",
      "|         black_stork|  248|\n",
      "|        fox_squirrel|  241|\n",
      "+--------------------+-----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
